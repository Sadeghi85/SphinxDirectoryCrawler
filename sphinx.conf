

source lib_eshia_ir_main
{
	type			= mysql

	sql_host		= 127.0.0.1
	sql_user		= Sphinx
	sql_pass		= Sphinx_Pass
	sql_db			= sphinx_lib_eshia_ir
	#sql_db			= sphinx_test

	#mysql_connect_flags	= 32 # enable compression

	sql_query_pre		= SET NAMES utf8
	# sql_query_pre		= SET SESSION query_cache_type=OFF

	sql_query_pre = REPLACE INTO documents_last_main_reindex SELECT 1, UNIX_TIMESTAMP()
	sql_query_pre = TRUNCATE TABLE documents_deleted
	# main document fetch query
	# mandatory, integer document ID field MUST be the first selected column
	sql_query		= \
		SELECT id, path, modified_at, bookid, bookid_hash, volume, volume_hash, page, page_hash \
		FROM documents \
		WHERE auto_id>=$start AND auto_id<=$end AND modified_at <= ( SELECT last_reindex FROM documents_last_main_reindex WHERE id=1 )

	#sql_query		= \
	#	SELECT id, path, modified_at \
	#	FROM documents \
	#	WHERE modified_at <= ( SELECT last_reindex FROM documents_last_main_reindex WHERE id=1 )


	# file based field declaration
	#
	# content of this field is treated as a file name
	# and the file gets loaded and indexed in place of a field
	#
	# max file size is limited by max_file_field_buffer indexer setting
	# file IO errors are non-fatal and get reported as warnings
	#
	sql_file_field		= path

	# range query setup, query that must return min and max ID values
	# optional, default is empty
	#
	# sql_query will need to reference $start and $end boundaries
	# if using ranged query:
	#
	# sql_query		= \
	#	SELECT doc.id, doc.id AS group, doc.title, doc.data \
	#	FROM documents doc \
	#	WHERE id>=$start AND id<=$end
	#
	sql_query_range		= SELECT MIN(auto_id),MAX(auto_id) FROM documents

	# range query step
	# optional, default is 1024
	#
	sql_range_step		= 3000

	# UNIX timestamp attribute declaration
	# multi-value (an arbitrary number of attributes is allowed), optional
	# similar to integer, but can also be used in date functions
	#
	# sql_attr_timestamp	= posted_ts
	# sql_attr_timestamp	= last_edited_ts
	# sql_attr_timestamp	= date_added
	sql_attr_timestamp	= modified_at

	# string attribute declaration
	# multi-value (an arbitrary number of these is allowed), optional
	# lets you store and retrieve strings
	#
	#sql_attr_string		= stitle
	
	sql_attr_string		= bookid
	sql_attr_string		= volume
	sql_attr_string		= page
	
	sql_attr_uint		= bookid_hash
	sql_attr_uint		= volume_hash
	sql_attr_uint		= page_hash
	
	# combined field plus attribute declaration (from a single column)
	# stores column as an attribute, but also indexes it as a full-text field
	#
	sql_field_string	= path
	# sql_field_str2wordcount	= title

	# post-query, executed on sql_query completion
	# optional, default is empty
	#
	# sql_query_post		=

	
	# post-index-query, executed on successful indexing completion
	# optional, default is empty
	# $maxid expands to max document ID actually fetched from DB
	#
	# sql_query_post_index	= REPLACE INTO counters ( id, val ) \
	#	VALUES ( 'max_indexed_id', $maxid )


	# ranged query throttling, in milliseconds
	# optional, default is 0 which means no delay
	# enforces given delay before each query step
	#sql_ranged_throttle	= 50

	# document info query, ONLY for CLI search (ie. testing and debugging)
	# optional, default is empty
	# must contain $id macro and must fetch the document by that id
	#sql_query_info		= SELECT * FROM documents WHERE id=$id

	# kill-list query, fetches the document IDs for kill-list
	# k-list will suppress matches from preceding indexes in the same query
	# optional, default is empty
	#
	sql_query_killlist	= SELECT id FROM documents_deleted UNION SELECT id FROM documents \
		WHERE modified_at > ( SELECT last_reindex FROM documents_last_main_reindex WHERE id=1 )

}

source lib_eshia_ir_delta : lib_eshia_ir_main
{
    sql_query_pre = SET NAMES utf8
	# sql_query		= \
		# SELECT id, path, modified_at \
		# FROM documents \
		# WHERE id>=$start AND id<=$end AND modified_at > ( SELECT last_reindex FROM documents_last_main_reindex WHERE id=1 )

	sql_query		= \
		SELECT id, path, modified_at, bookid, volume, page \
		FROM documents \
		WHERE modified_at > ( SELECT last_reindex FROM documents_last_main_reindex WHERE id=1 )
}

index lib_eshia_ir_main
{

	type			= plain

	# document source(s) to index
	# multi-value, mandatory
	# document IDs must be globally unique across all sources
	source			= lib_eshia_ir_main

	# index files path and file name, without extension
	# mandatory, path must be writable, extensions will be auto-appended
	path			= c:/sphinx-2.2.3-beta-win64/data/lib_eshia_ir_main

	# document attribute values (docinfo) storage mode
	# optional, default is 'extern'
	# known values are 'none', 'extern' and 'inline'
	docinfo			= extern

	# dictionary type, 'crc' or 'keywords'
	# crc is faster to index when no substring/wildcards searches are needed
	# crc with substrings might be faster to search but is much slower to index
	# (because all substrings are pre-extracted as individual keywords)
	# keywords is much faster to index with substrings, and index is much (3-10x) smaller
	# keywords supports wildcards, crc does not, and never will
	# optional, default is 'crc'
	dict			= keywords

	# memory locking for cached data (.spa and .spi), to prevent swapping
	# optional, default is 0 (do not mlock)
	# requires searchd to be run from root
	mlock			= 0

	# a list of morphology preprocessors to apply
	# optional, default is empty
	#
	# builtin preprocessors are 'none', 'stem_en', 'stem_ru', 'stem_enru',
	# 'soundex', and 'metaphone'; additional preprocessors available from
	# libstemmer are 'libstemmer_XXX', where XXX is algorithm code
	# (see libstemmer_c/libstemmer/modules.txt)
	#
	# morphology		= stem_en, stem_ru, soundex
	# morphology		= libstemmer_german
	# morphology		= libstemmer_sv
	morphology		= stem_ar

	# minimum word length at which to enable stemming
	# optional, default is 1 (stem everything)
	#
	min_stemming_len	= 2


	# stopword files list (space separated)
	# optional, default is empty
	# contents are plain text, charset_table and stemming are both applied
	#
	# stopwords		= c:/sphinx-2.2.3-beta-win64/data/stopwords.txt

	# minimum indexed word length
	# default is 1 (index everything)
	min_word_len		= 2

	# charset encoding type
	# optional, default is 'sbcs'
	# known types are 'sbcs' (Single Byte CharSet) and 'utf-8'
	#charset_type		= utf-8

	# charset definition and case folding rules "table"
	# optional, default value depends on charset_type
	#
	# defaults are configured to include English and Russian characters only
	# you need to change the table to include additional ones
	# this behavior MAY change in future versions
	#
	# 'sbcs' default value is
	# charset_table		= 0..9, A..Z->a..z, _, a..z, U+A8->U+B8, U+B8, U+C0..U+DF->U+E0..U+FF, U+E0..U+FF
	#
	# 'utf-8' default value is
	# charset_table		= 0..9, A..Z->a..z, _, a..z, U+410..U+42F->U+430..U+44F, U+430..U+44F
	
	# Arabic
	charset_table		= 0..9, a..z, \
	A..Z->a..z, \
	\
	U+0622, U+0627..U+063A, U+0641..U+0648, U+064A, U+067E, U+0686, U+0698, U+06AF, \
	\
	U+FB56->U+067E, U+FB57->U+067E, U+FB58->U+067E, U+FB59->U+067E, \
	U+FB7A->U+0686, U+FB7B->U+0686, U+FB7C->U+0686, U+FB7D->U+0686, \
	U+FB8A->U+0698, U+FB8B->U+0698, \
	U+FB92->U+06AF, U+FB93->U+06AF, U+FB94->U+06AF, U+FB95->U+06AF, \
	U+0623->U+0627, U+0625->U+0627, U+0671->U+0627, U+0672->U+0627, U+0673->U+0627, U+0675->U+0627, U+FB50->U+0627, U+FB51->U+0627, \
	U+06A9->U+0643, U+FB8E->U+0643, U+FB8F->U+0643, U+FB90->U+0643, U+FB91->U+0643, \
	U+0624->U+0648, U+0676->U+0648, \
	U+06BE->U+0647, U+06C1->U+0647, U+06C2->U+0647, U+06C0->U+0647, U+06D5->U+0647, U+FBAA->U+0647, U+FBAB->U+0647, U+FBAC->U+0647, U+FBAD->U+0647, U+FBA4->U+0647, U+FBA5->U+0647, U+FBA6->U+0647, U+FBA7->U+0647, U+FBA8->U+0647, U+FBA9->U+0647, \
	U+0626->U+064A, U+0649->U+064A, U+0678->U+064A, U+06CC->U+064A, U+FBFC->U+064A, U+FBFD->U+064A, U+FBFE->U+064A, U+FBFF->U+064A, U+FBE8->U+064A, U+FBAE->U+064A, U+FBAF->U+064A, U+FBB0->U+064A, U+FBB1->U+064A, U+06D0->U+064A, U+06D1->U+064A, U+06D2->U+064A, U+06D3->U+064A, U+FBE4->U+064A, U+FBE5->U+064A, U+FBE6->U+064A, U+FBE7->U+064A, \
	U+06C3->U+0629, \
	\
	U+0660->U+0030, U+06F0->U+0030, \
	U+0661->U+0031, U+06F1->U+0031, \
	U+0662->U+0032, U+06F2->U+0032, \
	U+0663->U+0033, U+06F3->U+0033, \
	U+0664->U+0034, U+06F4->U+0034, \
	U+0665->U+0035, U+06F5->U+0035, \
	U+0666->U+0036, U+06F6->U+0036, \
	U+0667->U+0037, U+06F7->U+0037, \
	U+0668->U+0038, U+06F8->U+0038, \
	U+0669->U+0039, U+06F9->U+0039

	# ignored characters list
	# optional, default value is empty
	#
	ignore_chars		= \
	\
	U+0618..U+061A, U+0640, U+064B..U+065F, U+066B..U+066C, U+0670, U+0674, U+06D4, U+06D6..U+06ED, \
	U+00AD


	# minimum word prefix length to index
	# optional, default is 0 (do not index prefixes)
	#
	#min_prefix_len		= 3


	# minimum word infix length to index
	# optional, default is 0 (do not index infixes)
	#
	#min_infix_len		= 2


	# maximum substring (prefix or infix) length to index
	# optional, default is 0 (do not limit substring length)
	#
	# max_substring_len	= 8


	# list of fields to limit prefix/infix indexing to
	# optional, default value is empty (index all fields in prefix/infix mode)
	#
	#prefix_fields		= path
	#infix_fields		= path


	# enable star-syntax (wildcards) when searching prefix/infix indexes
	# search-time only, does not affect indexing, can be 0 or 1
	# optional, default is 0 (do not use wildcard syntax)
	#
	#enable_star		= 1


	# expand keywords with exact forms and/or stars when searching fit indexes
	# search-time only, does not affect indexing, can be 0 or 1
	# optional, default is 0 (do not expand keywords)
	#
	expand_keywords		= 1

	
	# n-gram length to index, for CJK indexing
	# only supports 0 and 1 for now, other lengths to be implemented
	# optional, default is 0 (disable n-grams)
	#
	# ngram_len		= 1


	# n-gram characters list, for CJK indexing
	# optional, default is empty
	#
	# ngram_chars		= U+3000..U+2FA1F


	# phrase boundary characters list
	# optional, default is empty
	#
	# phrase_boundary		= ., ?, !, U+2026 # horizontal ellipsis


	# phrase boundary word position increment
	# optional, default is 0
	#
	# phrase_boundary_step	= 100


	# blended characters list
	# blended chars are indexed both as separators and valid characters
	# for instance, AT&T will results in 3 tokens ("at", "t", and "at&t")
	# optional, default is empty
	#
	blend_chars		= \
	\
	_, U+003D, U+0621, U+200C
	#+, &, U+23


	# blended token indexing mode
	# a comma separated list of blended token indexing variants
	# known variants are trim_none, trim_head, trim_tail, trim_both, skip_pure
	# optional, default is trim_none
	#
	blend_mode		= trim_none, skip_pure


	# whether to strip HTML tags from incoming documents
	# known values are 0 (do not strip) and 1 (do strip)
	# optional, default is 0
	html_strip		= 1

	# what HTML attributes to index if stripping HTML
	# optional, default is empty (do not index anything)
	#
	# html_index_attrs	= img=alt,title; a=title;
	html_index_attrs	= a=title;


	# what HTML elements contents to strip
	# optional, default is empty (do not strip element contents)
	#
	html_remove_elements	= style, script


	# whether to preopen index data files on startup
	# optional, default is 0 (do not preopen), searchd-only
	#
	preopen			= 1


	# whether to keep dictionary (.spi) on disk, or cache it in RAM
	# optional, default is 0 (cache in RAM), searchd-only
	#
	# ondisk_dict		= 1


	# whether to enable in-place inversion (2x less disk, 90-95% speed)
	# optional, default is 0 (use separate temporary files), indexer-only
	#
	# inplace_enable		= 1


	# in-place fine-tuning options
	# optional, defaults are listed below
	#
	# inplace_hit_gap		= 0 # preallocated hitlist gap size
	# inplace_docinfo_gap	= 0 # preallocated docinfo gap size
	# inplace_reloc_factor	= 0.1 # relocation buffer size within arena
	# inplace_write_factor	= 0.1 # write buffer size within arena


	# whether to index original keywords along with stemmed versions
	# enables "=exactform" operator to work
	# optional, default is 0
	#
	index_exact_words	= 1


	# position increment on overshort (less that min_word_len) words
	# optional, allowed values are 0 and 1, default is 1
	#
	# overshort_step		= 1


	# position increment on stopword
	# optional, allowed values are 0 and 1, default is 1
	#
	# stopword_step		= 1


	# hitless words list
	# positions for these keywords will not be stored in the index
	# optional, allowed values are 'all', or a list file name
	#
	# hitless_words		= all
	# hitless_words		= hitless.txt


	# detect and index sentence and paragraph boundaries
	# required for the SENTENCE and PARAGRAPH operators to work
	# optional, allowed values are 0 and 1, default is 0
	#
	index_sp			= 1


	# index zones, delimited by HTML/XML tags
	# a comma separated list of tags and wildcards
	# required for the ZONE operator to work
	# optional, default is empty string (do not index zones)
	#
	# index_zones		= title, h*, th
	index_zones		= title


	# index per-document and average per-index field lengths, in tokens
	# required for the BM25A(), BM25F() in expression ranker
	# optional, default is 0 (do not index field lenghts)
	#
	index_field_lengths	= 0


	# regular expressions (regexps) to filter the fields and queries with
	# gets applied to data source fields when indexing
	# gets applied to search queries when searching
	# multi-value, optional, default is empty list of regexps
	#
	# regexp_filter		= \b(\d+)\" => \1inch
	# regexp_filter		= (blue|red) => color


	# list of the words considered frequent with respect to bigram indexing
	# optional, default is empty
	#
	# bigram_freq_words	= the, a, i, you, my


	# bigram indexing mode
	# known values are none, all, first_freq, both_freq
	# option, default is none (do not index bigrams)
	#
	# bigram_index		= both_freq


	# snippet document file name prefix
	# preprended to file names when generating snippets using load_files option
	# WARNING, this is a prefix (not a path), trailing slash matters!
	# optional, default is empty
	#
	# snippets_file_prefix	= /mnt/mydocs/server1


	# whether to apply stopwords before or after stemming
	# optional, default is 0 (apply stopwords after stemming)
	#
	# stopwords_unstemmed	= 0

}


index lib_eshia_ir_delta : lib_eshia_ir_main
{
	source			= lib_eshia_ir_delta

	# index files path and file name, without extension
	# mandatory, path must be writable, extensions will be auto-appended
	path			= c:/sphinx-2.2.3-beta-win64/data/lib_eshia_ir_delta

}

index lib_eshia_ir
{
	# 'distributed' index type MUST be specified
	type			= distributed

	# local index to be searched
	# there can be many local indexes configured
	local			= lib_eshia_ir_main
	local			= lib_eshia_ir_delta

}

indexer
{
	# memory limit, in bytes, kiloytes (16384K) or megabytes (256M)
	# optional, default is 32M, max is 2047M, recommended is 256M to 1024M
	mem_limit		= 1024M

	# maximum IO calls per second (for I/O throttling)
	# optional, default is 0 (unlimited)
	#
	# max_iops		= 40


	# maximum IO call size, bytes (for I/O throttling)
	# optional, default is 0 (unlimited)
	#
	# max_iosize		= 1048576


	# maximum xmlpipe2 field length, bytes
	# optional, default is 2M
	#
	# max_xmlpipe2_field	= 4M


	# write buffer size, bytes
	# several (currently up to 4) buffers will be allocated
	# write buffers are allocated in addition to mem_limit
	# optional, default is 1M
	#
	# write_buffer		= 1M


	# maximum file field adaptive buffer size
	# optional, default is 8M, minimum is 1M
	#
	# max_file_field_buffer	= 32M


	# how to handle IO errors in file fields
	# known values are 'ignore_field', 'skip_document', and 'fail_index'
	# optional, default is 'ignore_field'
	#
	on_file_field_error = skip_document


	# lemmatizer dictionaries base path
	# optional, defaut is /usr/local/share (see ./configure --datadir)
	#
	# lemmatizer_base = /usr/local/share/sphinx/dicts


	# lemmatizer cache size
	# improves the indexing time when the lemmatization is enabled
	# optional, default is 256K
	#
	# lemmatizer_cache = 512M
}


searchd
{
	# [hostname:]port[:protocol], or /unix/socket/path to listen on
	# known protocols are 'sphinx' (SphinxAPI) and 'mysql41' (SphinxQL)
	#
	# multi-value, multiple listen points are allowed
	# optional, defaults are 9312:sphinx and 9306:mysql41, as below
	#
	# listen			= 127.0.0.1
	# listen			= 192.168.0.1:9312
	# listen			= 9312
	# listen			= /var/run/searchd.sock
	listen			= 127.0.0.1:9312
	#listen			= 9306:mysql41

	# log file, searchd run info is logged here
	# optional, default is 'searchd.log'
	log			= c:/sphinx-2.2.3-beta-win64/log/searchd.log

	# query log file, all search queries are logged here
	# optional, default is empty (do not log queries)
	#query_log		= c:/sphinx-2.2.3-beta-win64/log/query.log

	# client read timeout, seconds
	# optional, default is 5
	read_timeout		= 5

	# request timeout, seconds
	# optional, default is 5 minutes
	client_timeout		= 30

	# maximum amount of children to fork (concurrent searches to run)
	# optional, default is 0 (unlimited)
	max_children		= 30

	# maximum amount of persistent connections from this master to each agent host
	# optional, but necessary if you use agent_persistent. It is reasonable to set the value
	# as max_children, or less on the agent's hosts.
	persistent_connections_limit	= 30

	# PID file, searchd process ID file name
	# mandatory
	pid_file		= c:/sphinx-2.2.3-beta-win64/log/searchd.pid

	# max amount of matches the daemon ever keeps in RAM, per-index
	# WARNING, THERE'S ALSO PER-QUERY LIMIT, SEE SetLimits() API CALL
	# default is 1000 (just like Google)
	#max_matches		= 1000

	# seamless rotate, prevents rotate stalls if precaching huge datasets
	# optional, default is 1
	seamless_rotate		= 1

	# whether to forcibly preopen all indexes on startup
	# optional, default is 1 (preopen everything)
	preopen_indexes		= 1

	# whether to unlink .old index copies on succesful rotation.
	# optional, default is 1 (do unlink)
	unlink_old		= 1

	# attribute updates periodic flush timeout, seconds
	# updates will be automatically dumped to disk this frequently
	# optional, default is 0 (disable periodic flush)
	#
	# attr_flush_period	= 900


	# instance-wide ondisk_dict defaults (per-index value take precedence)
	# optional, default is 0 (precache all dictionaries in RAM)
	#
	# ondisk_dict_default	= 1


	# MVA updates pool size
	# shared between all instances of searchd, disables attr flushes!
	# optional, default size is 1M
	mva_updates_pool	= 1M

	# max allowed network packet size
	# limits both query packets from clients, and responses from agents
	# optional, default size is 8M
	max_packet_size		= 8M

	# crash log path
	# searchd will (try to) log crashed query to 'crash_log_path.PID' file
	# optional, default is empty (do not create crash logs)
	#
	# crash_log_path		= c:/sphinx-2.2.3-beta-win64/log/crash


	# max allowed per-query filter count
	# optional, default is 256
	max_filters		= 256

	# max allowed per-filter values count
	# optional, default is 4096
	max_filter_values	= 15000


	# socket listen queue length
	# optional, default is 5
	#
	# listen_backlog		= 5


	# per-keyword read buffer size
	# optional, default is 256K
	#
	read_buffer		= 1M


	# unhinted read size (currently used when reading hits)
	# optional, default is 32K
	#
	read_unhinted		= 512K


	# max allowed per-batch query count (aka multi-query count)
	# optional, default is 32
	max_batch_queries	= 32


	# max common subtree document cache size, per-query
	# optional, default is 0 (disable subtree optimization)
	#
	subtree_docs_cache	= 4M


	# max common subtree hit cache size, per-query
	# optional, default is 0 (disable subtree optimization)
	#
	subtree_hits_cache	= 32M


	# multi-processing mode (MPM)
	# known values are none, fork, prefork, and threads
	# threads is required for RT backend to work
	# optional, default is fork
	workers			= threads # for RT to work


	# max threads to create for searching local parts of a distributed index
	# optional, default is 0, which means disable multi-threaded searching
	# should work with all MPMs (ie. does NOT require workers=threads)
	#
	dist_threads		= 4


	# binlog files path; use empty string to disable binlog
	# optional, default is build-time configured data directory
	#
	# binlog_path		= # disable logging
	binlog_path		= c:/sphinx-2.2.3-beta-win64/data # binlog.001 etc will be created there


	# binlog flush/sync mode
	# 0 means flush and sync every second
	# 1 means flush and sync every transaction
	# 2 means flush every transaction, sync every second
	# optional, default is 2
	#
	binlog_flush		= 2


	# binlog per-file size limit
	# optional, default is 128M, 0 means no limit
	#
	binlog_max_log_size	= 128M


	# per-thread stack size, only affects workers=threads mode
	# optional, default is 64K
	#
	thread_stack			= 1M


	# per-keyword expansion limit (for dict=keywords prefix searches)
	# optional, default is 0 (no limit)
	#
	# expansion_limit		= 1000

	# query log file format
	# optional, known values are plain and sphinxql, default is plain
	#
	# query_log_format		= sphinxql


	# version string returned to MySQL network protocol clients
	# optional, default is empty (use Sphinx version)
	#
	mysql_version_string	= 5.0.37


	# trusted plugin directory
	# optional, default is empty (disable UDFs)
	#
	# plugin_dir			= /usr/local/sphinx/lib


	# default server-wide collation
	# optional, default is libc_ci
	#
	collation_server		= utf8_general_ci


	# server-wide locale for libc based collations
	# optional, default is C
	#
	# collation_libc_locale	= ru_RU.UTF-8


	# threaded server watchdog (only used in workers=threads mode)
	# optional, values are 0 and 1, default is 1 (watchdog on)
	#
	# watchdog				= 1

	
	# SphinxQL compatibility mode (legacy columns and their names)
	# optional, default is 1 (old-style)
	#
	# compat_sphinxql_magics	= 1


	# costs for max_predicted_time model, in (imaginary) nanoseconds
	# optional, default is "doc=64, hit=48, skip=2048, match=64"
	#
	# predicted_time_costs	= doc=64, hit=48, skip=2048, match=64


}